{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYDL_dCEoEdH",
        "outputId": "5bf2b469-f05a-4924-fbb1-b8f1a6ca2387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import copy\n",
        "import wandb\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Seeds for reproducibility\n",
        "def set_seed(seed: int = 123):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(123)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd1AgVLg-UaB"
      },
      "outputs": [],
      "source": [
        "\"\"\" PLOT SETTINGS \"\"\"\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 18,            # base font size\n",
        "    \"axes.titlesize\": 24,       # axis titles\n",
        "    \"axes.labelsize\": 22,       # axis labels\n",
        "    \"xtick.labelsize\": 18,      # X axis numbers\n",
        "    \"ytick.labelsize\": 18,      # Y axis numbers\n",
        "    \"legend.fontsize\": 20,      # legend text\n",
        "    \"lines.linewidth\": 3.0      # line thickness\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss-OkMVT6W1r"
      },
      "outputs": [],
      "source": [
        "\"\"\" CLASS TO CREATE THE HEAD with 100 CLASSES \"\"\"\n",
        "class DINOWithHead(nn.Module):\n",
        "    def __init__(self, backbone, num_classes=100, p=None):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        layers = []\n",
        "        if p is not None:\n",
        "            layers.append(nn.Dropout(p=p))\n",
        "        layers.append(nn.Linear(384, num_classes))\n",
        "        self.head = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        return self.head(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJtMX7-9Z5_D"
      },
      "source": [
        "### Dataset Download and Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyyFR5pwqFuv",
        "outputId": "e973bf0e-8631-4d4f-db23-2327c2d0a27b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:03<00:00, 48.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\" DATASET DOWNLOAD \"\"\"\n",
        "\n",
        "ROOT = './data'\n",
        "BATCH_SIZE = 64\n",
        "#BATCH_SIZE = 128\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "tot_train_data = torchvision.datasets.CIFAR100(root=ROOT, train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.CIFAR100(root=ROOT, train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvBGsuJ9qMeY"
      },
      "outputs": [],
      "source": [
        "\"\"\" SPLIT TOT_TRAININ in VALIDATION and TRAIN \"\"\"\n",
        "\n",
        "def split_dataset(tot_train_data, valid_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Splits the given dataset randomly into training and validation subsets.\n",
        "    \"\"\"\n",
        "    train_size = int(valid_ratio * len(tot_train_data))\n",
        "    val_size = len(tot_train_data) - train_size\n",
        "    train_data, val_data = random_split(tot_train_data, [train_size, val_size])\n",
        "    return train_data, val_data\n",
        "\n",
        "train_data, val_data = split_dataset(tot_train_data, valid_ratio=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnpYR9U0annj"
      },
      "outputs": [],
      "source": [
        "\"\"\" DATA TRANSFORMATION \"\"\"\n",
        "\n",
        "def data_trasform(dataset, data_augmentation=False):   ### train_data or tot_train_data\n",
        "    \"\"\"\n",
        "    Returns train and val/test transforms based on dataset stats.\n",
        "    Dataset (for computing mean and std) can be either training only or combined train+validation.\n",
        "\n",
        "    If data_augmentation=True, applies augmentation on training transforms, otherwise only resize and normalize.\n",
        "    \"\"\"\n",
        "\n",
        "    # MEAN and VARIANCE (considering 3 channels)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    nb_samples = 0\n",
        "\n",
        "    for img, _ in dataset:\n",
        "        img = img.view(3, -1)  # Flatten H*W in seconda dimensione\n",
        "        mean += img.mean(1)\n",
        "        std += img.std(1)\n",
        "        nb_samples += 1\n",
        "\n",
        "    mean /= nb_samples\n",
        "    std /= nb_samples\n",
        "\n",
        "\n",
        "    if data_augmentation:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize(64, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.RandomCrop(64, padding=4),\n",
        "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "    else:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize(64, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "\n",
        "    ### NO DATA AUGMENTATION for val/test!\n",
        "    val_test_transforms = transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std)   # Normalization using the training statistics\n",
        "    ])\n",
        "\n",
        "\n",
        "    return train_transforms, val_test_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY7RBmCoaQeT"
      },
      "outputs": [],
      "source": [
        "\"\"\" DATA TRANSFORMATION and LOADERS \"\"\"\n",
        "\n",
        "### ===== For hyperparameter tuning considering train_data and val_data =====\n",
        "train_transforms, val_test_transforms = data_trasform(train_data)\n",
        "\n",
        "train_data.dataset.transform = train_transforms\n",
        "val_data.dataset.transform = val_test_transforms\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader   = DataLoader(val_data,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "\n",
        "### ===== For model testing considering tot_train_data and test_data =====\n",
        "train_transforms, val_test_transforms = data_trasform(tot_train_data)\n",
        "\n",
        "tot_train_data = torchvision.datasets.CIFAR100(root=ROOT, train=True, download=False, transform=train_transforms)\n",
        "test_data = torchvision.datasets.CIFAR100(root=ROOT, train=False, download=False, transform=val_test_transforms)\n",
        "\n",
        "tot_train_loader = DataLoader(tot_train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImlDNxZRqdzk"
      },
      "source": [
        "### Test and Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2wJEmef0SdF"
      },
      "outputs": [],
      "source": [
        "\"\"\" TRAINING and TESTING \"\"\"\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    \"\"\"\n",
        "    The evaluate_model function computes the average loss and accuracy of a model on a dataset.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader.dataset)\n",
        "    avg_acc = total_corrects.double() / len(data_loader.dataset)\n",
        "    return avg_loss, avg_acc.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, scheduler, epoch, train_losses, train_accuracies,\n",
        "                    val_test_losses, val_test_accuracies, best_acc, best_loss, best_model_wts, path):\n",
        "    \"\"\"\n",
        "    The save_checkpoint function saves the model’s state, optimizer, scheduler, training/validation metrics,\n",
        "    and best performance to a specified file path.\n",
        "    \"\"\"\n",
        "    dir_name = os.path.dirname(path)\n",
        "    if dir_name:\n",
        "        os.makedirs(dir_name, exist_ok=True)\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_test_losses': val_test_losses,\n",
        "        'val_test_accuracies': val_test_accuracies,\n",
        "        'best_acc': best_acc,\n",
        "        'best_loss': best_loss,\n",
        "        'best_model_state_dict': best_model_wts\n",
        "    }\n",
        "    torch.save(checkpoint, path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def init_checkpoint(model, optimizer, scheduler, path=None, device='cpu'):\n",
        "    \"\"\"\n",
        "    Initialize a checkpoint. If path is None, create default checkpoint with empty/default values.\n",
        "    If path is given and file exists, load it.\n",
        "    \"\"\"\n",
        "    if path is None:  # default path\n",
        "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "        path = \"checkpoints/latest.pth\"\n",
        "        print(f\"Initializing new checkpoint at {path}\")\n",
        "        checkpoint = {   # save default empty checkpoint\n",
        "            'epoch': 1,\n",
        "            'best_acc': 0.0,\n",
        "            'best_loss': 1e10,\n",
        "            'train_losses': [],\n",
        "            'train_accuracies': [],\n",
        "            'val_test_losses': [],\n",
        "            'val_test_accuracies': [],\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "            'best_model_state_dict': copy.deepcopy(model.state_dict())\n",
        "        }\n",
        "        torch.save(checkpoint, path)\n",
        "        return 1, 0.0, 1e10, [], [], [], [], path, copy.deepcopy(model.state_dict())\n",
        "\n",
        "    else: # load existing checkpoint\n",
        "        if not os.path.isfile(path):\n",
        "            raise FileNotFoundError(f\"Checkpoint file {path} does not exist.\")\n",
        "\n",
        "        print(f\"Loading checkpoint from {path}\")\n",
        "        checkpoint = torch.load(path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        if scheduler and checkpoint.get('scheduler_state_dict'):\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        best_model_wts = checkpoint.get('best_model_state_dict', copy.deepcopy(model.state_dict()))\n",
        "        return (checkpoint['epoch'],\n",
        "                checkpoint.get('best_acc', 0.0),\n",
        "                checkpoint.get('best_loss', 1e10),\n",
        "                checkpoint.get('train_losses', []),\n",
        "                checkpoint.get('train_accuracies', []),\n",
        "                checkpoint.get('val_test_losses', []),\n",
        "                checkpoint.get('val_test_accuracies', []),\n",
        "                path,\n",
        "                best_model_wts )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_test_model(model, criterion, optimizer, scheduler, train_loader, val_test_loader,\n",
        "                          num_epochs=10, checkpoint_path=None, checkpoints = True, verbose = 1):\n",
        "                                        # If checkpoint_path = None, a path is created and training starts from scratch\n",
        "                                        # If checkpoints = False, we don't save anything (used for the calibration part)\n",
        "    \"\"\"\n",
        "    Trains a model with logging and evaluation, returning the best model and metrics.\n",
        "    If a checkpoint path is provided, training will resume from the saved state in that file.\n",
        "    \"\"\"\n",
        "\n",
        "    since = time.time()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # === Checkpoints (Initialize if None, Load if it exists already) ===\n",
        "    if checkpoints: # Training with checkpoints\n",
        "        start_epoch, best_acc, best_loss, train_losses, train_accuracies, val_test_losses, val_test_accuracies, checkpoint_path, best_model_wts = \\\n",
        "            init_checkpoint(model, optimizer, scheduler, path=checkpoint_path, device=device)\n",
        "\n",
        "    else: # No checkpoint\n",
        "        start_epoch = 1\n",
        "        best_acc = 0.0\n",
        "        best_loss = 1e10\n",
        "        train_losses, train_accuracies, val_test_losses, val_test_accuracies = [], [], [], []\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # ===== Epoch loop =====\n",
        "    for epoch in range(start_epoch, num_epochs+1):\n",
        "        if checkpoints:\n",
        "            if verbose:\n",
        "                print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "                print('-' * 30)\n",
        "\n",
        "        # ===== Training =====\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_corrects = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = train_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        if len(train_losses) >= epoch:     # Overwriting the current epoch's results if resuming from this position (if the current loop was never compelted)\n",
        "            train_losses[epoch-1] = epoch_train_loss\n",
        "            train_accuracies[epoch-1] = epoch_train_acc.item()\n",
        "        else:\n",
        "            train_losses.append(epoch_train_loss)\n",
        "            train_accuracies.append(epoch_train_acc.item())\n",
        "\n",
        "        if verbose == True:  # Print each round\n",
        "            print(f'Train Loss: {epoch_train_loss:.4f} Train Acc: {epoch_train_acc:.4f}')\n",
        "\n",
        "\n",
        "        # ===== Validation/Test =====\n",
        "        epoch_val_test_loss, epoch_val_test_acc = evaluate_model(model, val_test_loader, criterion)\n",
        "\n",
        "        if len(val_test_losses) >= epoch:    # Overwriting the current epoch's results if resuming from this position\n",
        "            val_test_losses[epoch-1] = epoch_val_test_loss\n",
        "            val_test_accuracies[epoch-1] = epoch_val_test_acc\n",
        "        else:\n",
        "            val_test_losses.append(epoch_val_test_loss)\n",
        "            val_test_accuracies.append(epoch_val_test_acc)\n",
        "        if verbose == True:\n",
        "            print(f'Val/Test Loss: {epoch_val_test_loss:.4f}, Val/Test Acc: {epoch_val_test_acc:.4f}')\n",
        "\n",
        "        if verbose == 'mid':\n",
        "            if epoch == 1 or epoch % 5 == 0:   # Print occasionally\n",
        "                print(f\"Epoch {epoch}\")\n",
        "                print(f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}')\n",
        "                print(f'Val/Test Loss: {epoch_val_test_loss:.4f}, Val/Test Acc: {epoch_val_test_acc:.4f}')\n",
        "\n",
        "        # ===== Update and Save the best model =====\n",
        "        if epoch_val_test_acc > best_acc:\n",
        "            best_acc = epoch_val_test_acc\n",
        "            best_loss = epoch_val_test_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # ===== Save checkpoint =====\n",
        "        if checkpoints:\n",
        "            save_checkpoint(\n",
        "                model, optimizer, scheduler,\n",
        "                epoch + 1,\n",
        "                train_losses, train_accuracies,\n",
        "                val_test_losses, val_test_accuracies,\n",
        "                best_acc, best_loss, best_model_wts,\n",
        "                checkpoint_path\n",
        "            )\n",
        "\n",
        "    # Training completed\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best Acc: {best_acc:.4f}, Best Loss: {best_loss:.4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, train_losses, val_test_losses, train_accuracies, val_test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN3CjZW2JPVj"
      },
      "source": [
        "# (2) CENTRALIZED MODEL with SPARSE FINE-TUNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yIKXBT6W1x"
      },
      "source": [
        "### Functions for Masking & Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfLak3bY6W1x"
      },
      "source": [
        "The Fisher Information Matrix F is a matrix that quantifies the sensitivity of the model to its parameters. Parameters that are more important have higher values in F, while less important parameters have lower values. <br>\n",
        "More precisely, it measures how the model's log-likelihood $ log p_\\theta(y|x) $ changes when the parameters $\\theta$ are modified. The Negative Log-Likelihood (NLL) is defined as: $$loss=−log p_\\theta(y|x)$$ <br>\n",
        "PyTorch computes the gradients of the loss with respect to all model parameters.\n",
        "Instead of computing the full Fisher Information Matrix, only its diagonal is approximated by accumulating the squared gradients over the batches:\n",
        "$$(\\nabla_\\theta \\log p_\\theta(y|x))^2$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OYCoNc6JM9a"
      },
      "outputs": [],
      "source": [
        "\"\"\" FISHER SCORES COMPUTATION, MASKING, FINE-TUNING \"\"\"\n",
        "\n",
        "\n",
        "def compute_fisher_scores(model, data_loader, device='cuda', max_batches = None):\n",
        "    \"\"\"\n",
        "    Compute diagonal Fisher Information scores.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    fisher_scores = {name: torch.zeros_like(param, device=\"cpu\")      # Initialize a dictionary to store Fisher Information scores\n",
        "                     for name, param in model.named_parameters() if param.requires_grad}\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        if max_batches is not None and i >= max_batches:    # Stop if a maximum number of batches is reached\n",
        "            break\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        model.zero_grad()   # Reset gradients\n",
        "        outputs = model(inputs)  # Forward pass through the model\n",
        "\n",
        "        log_probs = F.log_softmax(outputs, dim=1)   # Compute log-probabilities for each class\n",
        "        sampled_y = torch.multinomial(log_probs.exp(), num_samples=1).squeeze(-1)     # Sample a label from the predicted distribution for each input\n",
        "        loss = F.nll_loss(log_probs, sampled_y)    # Compute Negative Log-Likelihood loss with the sampled labels\n",
        "\n",
        "        loss.backward()  # Backpropagate to compute gradients\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                fisher_scores[name] += (param.grad.detach().cpu() ** 2)   # Accumulate squared gradients into the Fisher scores\n",
        "\n",
        "    # Normalize by dataset size\n",
        "    dataset_size = len(data_loader.dataset)\n",
        "    for name in fisher_scores.keys():\n",
        "        fisher_scores[name] /= dataset_size\n",
        "\n",
        "    return fisher_scores\n",
        "\n",
        "\n",
        "def calibrate_mask_centralized(model, train_loader, device='cuda', R=5, final_sparsity=0.9,\n",
        "                               lr=0.01, keep='least', do_train=True, max_batches=50, criterion=None, J=1):\n",
        "    \"\"\"\n",
        "    Progressive pruning mask for a centralized model using Fisher scores.\n",
        "    - R: number of calibration rounds\n",
        "    - final_sparsity: target fraction of parameters to prune\n",
        "    - keep: 'least', 'most', or 'random'\n",
        "    - do_train: whether to perform mini-training at each step\n",
        "    - max_batches: limit for Fisher computation\n",
        "    Returns: final mask (dict {param_name: tensor})\n",
        "    \"\"\"\n",
        "    if criterion is None:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initial mask: all ones for the trainable parameters\n",
        "    mask = {name: torch.ones_like(param, device=\"cpu\", dtype=torch.uint8)\n",
        "            for name, param in model.named_parameters() if param.requires_grad}\n",
        "\n",
        "    # List of trainable parameters\n",
        "    trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
        "\n",
        "    for r in range(1, R + 1):   # Calibration rounds\n",
        "        current_density = (1 - final_sparsity) ** (r / R)   # Represents the parameters to keep (mask==1)\n",
        "        current_sparsity = 1 - current_density              # Represents the parameters to freeze (mask==0)\n",
        "        print(f\"[Mask Round {r}] Target Sparsity: {current_sparsity:.4f}\")\n",
        "\n",
        "        fisher_scores = compute_fisher_scores(model, train_loader, device=device, max_batches=max_batches)\n",
        "\n",
        "        all_scores = torch.cat([score.view(-1) for score in fisher_scores.values()])   # Flatten all scores\n",
        "        num_keep_global = int(len(all_scores) * current_density)\n",
        "        num_keep_global = max(1, min(num_keep_global, len(all_scores)))       # Number of parameters to keep\n",
        "\n",
        "        # topk returns the top k largest or smallest values in a tensor along with their indices.\n",
        "        if keep == 'least':\n",
        "            _, idx = torch.topk(all_scores, k=num_keep_global, largest=False)\n",
        "        elif keep == 'most':\n",
        "            _, idx = torch.topk(all_scores, k=num_keep_global, largest=True)\n",
        "        elif keep == 'random':\n",
        "            idx = torch.randperm(len(all_scores))[:num_keep_global]\n",
        "        else:\n",
        "            raise ValueError(\"keep must be 'least', 'most', or 'random'\")\n",
        "\n",
        "        global_keep = torch.zeros_like(all_scores, dtype=torch.bool)     # All 0\n",
        "        global_keep[idx] = True                                          # True if to keep\n",
        "\n",
        "        # --- Redistribute the mask layer per layer ---\n",
        "        new_mask = {}    # To save the new updated mask\n",
        "        start = 0\n",
        "        for name, score in fisher_scores.items():\n",
        "            numel = score.numel()     # Number tot. of elements\n",
        "\n",
        "            # Selects the portion of the global boolean mask that corresponds to the current parameter\n",
        "            keep_tensor = global_keep[start:start+numel].view_as(score)      # Return to the original form\n",
        "\n",
        "            # Combining the newly selected elements (keep_tensor) with the previous mask, ensuring already frozen parameters remain inactive\n",
        "            new_mask[name] = (keep_tensor.to(torch.uint8) * mask[name])\n",
        "            start += numel  # Advances the start index for the next parameter\n",
        "\n",
        "        mask = new_mask\n",
        "\n",
        "        # Compute the total number of active parameters in the mask\n",
        "        total_ones = sum(m.sum().item() for m in mask.values())\n",
        "        total_params = sum(m.numel() for m in mask.values())\n",
        "        perc_active = 100 * total_ones / total_params\n",
        "        print(f\"Total active parameters in the mask: {total_ones} / {total_params} ({perc_active:.2f}%)\")\n",
        "\n",
        "        if do_train: #Mini-training, using SparseSGD\n",
        "            optimizer = SparseSGD(list(model.named_parameters()), lr=lr, mask=mask)\n",
        "            model.train()\n",
        "\n",
        "            J = 1 # If we want more then one training per calib.round J>1\n",
        "            for _ in range(J):\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb5HrMk-0SdM"
      },
      "outputs": [],
      "source": [
        "from torch.optim.optimizer import Optimizer    # To inherit  for the custom SparseSGD\n",
        "\n",
        "class SparseSGD(Optimizer):\n",
        "    \"\"\"\n",
        "    Sparse SGD with momentum and parameter masks (gradients corresponding to zeros in the mask are ignored)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, named_params, lr=0.01, momentum=0, weight_decay=0, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            params (iterable): model parameters to optimize\n",
        "            mask (dict {param_name: tensor} or None): a binary mask for the parameters.\n",
        "        \"\"\"\n",
        "        params = [p for _, p in named_params]\n",
        "        defaults = dict(lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "        super().__init__(params, defaults)  # initialize base Optimizer\n",
        "\n",
        "        # Initialize dictionary of parameter → mask mapping\n",
        "        self.masks = {}\n",
        "        if mask is not None:\n",
        "            # Iterate over model parameters with their names\n",
        "            for name, p in named_params:\n",
        "                # If a mask exists for this parameter name\n",
        "                if name in mask:\n",
        "                    # Map the parameter object to its corresponding mask tensor (= explicitly attaching the right mask tensor to the right parameter)\n",
        "                    self.masks[p] = mask[name].to(p.device)\n",
        "\n",
        "\n",
        "    @torch.no_grad()    ### decorator: ensures that everything inside this function by default does not track gradients.\n",
        "                        ### The function is manually updating model parameters, so we don’t want PyTorch to think these updates are part of the computational graph.\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "        \"\"\"\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for i, p in enumerate(group['params']):\n",
        "                if p.grad is None:\n",
        "                    continue  # skip parameters without gradients\n",
        "\n",
        "                d_p = p.grad  # get gradient\n",
        "\n",
        "                # Apply weight decay if specified\n",
        "                if group['weight_decay'] != 0:\n",
        "                    d_p = d_p.add(p, alpha=group['weight_decay'])\n",
        "\n",
        "                # Momentum: maintain a buffer to smooth updates\n",
        "                param_state = self.state[p]\n",
        "                if 'momentum_buffer' not in param_state:\n",
        "                    buf = param_state['momentum_buffer'] = d_p.clone()\n",
        "                else:\n",
        "                    buf = param_state['momentum_buffer']\n",
        "                    buf.mul_(group['momentum']).add_(d_p)\n",
        "                d_p = buf\n",
        "\n",
        "                # Apply sparse mask if provided\n",
        "                if self.masks is not None:\n",
        "                    mask = self.masks.get(p, None)\n",
        "                    if mask is not None:\n",
        "                        d_p = d_p * mask\n",
        "\n",
        "                # Update the parameter\n",
        "                p.add_(d_p, alpha=-group['lr'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9btQxxra2fM8",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## (2.I) Hyperparameter Selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alDhsbKR6W1y",
        "outputId": "c20be031-a4a6-47f7-f53d-c9c43423075c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/10\n",
            "------------------------------\n",
            "Train Loss: 2.1737 Train Acc: 0.5098\n",
            "Val/Test Loss: 1.2196 Acc: 0.6664\n",
            "\n",
            "Epoch 2/10\n",
            "------------------------------\n",
            "Train Loss: 0.9788 Train Acc: 0.7208\n",
            "Val/Test Loss: 1.0209 Acc: 0.7109\n",
            "\n",
            "Epoch 3/10\n",
            "------------------------------\n",
            "Train Loss: 0.7878 Train Acc: 0.7690\n",
            "Val/Test Loss: 0.9631 Acc: 0.7249\n",
            "\n",
            "Epoch 4/10\n",
            "------------------------------\n",
            "Train Loss: 0.6884 Train Acc: 0.7959\n",
            "Val/Test Loss: 0.9257 Acc: 0.7354\n",
            "\n",
            "Epoch 5/10\n",
            "------------------------------\n",
            "Train Loss: 0.6240 Train Acc: 0.8130\n",
            "Val/Test Loss: 0.9042 Acc: 0.7425\n",
            "\n",
            "Epoch 6/10\n",
            "------------------------------\n",
            "Train Loss: 0.5797 Train Acc: 0.8277\n",
            "Val/Test Loss: 0.8966 Acc: 0.7439\n",
            "\n",
            "Epoch 7/10\n",
            "------------------------------\n",
            "Train Loss: 0.5496 Train Acc: 0.8373\n",
            "Val/Test Loss: 0.8914 Acc: 0.7450\n",
            "\n",
            "Epoch 8/10\n",
            "------------------------------\n",
            "Train Loss: 0.5283 Train Acc: 0.8442\n",
            "Val/Test Loss: 0.8885 Acc: 0.7462\n",
            "\n",
            "Epoch 9/10\n",
            "------------------------------\n",
            "Train Loss: 0.5150 Train Acc: 0.8492\n",
            "Val/Test Loss: 0.8868 Acc: 0.7468\n",
            "\n",
            "Epoch 10/10\n",
            "------------------------------\n",
            "Train Loss: 0.5079 Train Acc: 0.8516\n",
            "Val/Test Loss: 0.8863 Acc: 0.7467\n",
            "\n",
            "Training complete in 3m 37s\n",
            "Best Acc: 0.7468, Best Loss: 0.8868\n",
            "{'epochs': 10, 'train_losses': [2.17366619682312, 0.9788436897277832, 0.787788997220993, 0.6884083556175232, 0.6239520938873291, 0.5796783101797104, 0.5495515852451325, 0.5283078512907028, 0.5150493123054505, 0.5078790948867797], 'train_accuracies': [0.50975, 0.72075, 0.7689750000000001, 0.795875, 0.8129500000000001, 0.827725, 0.8373, 0.8441500000000001, 0.8491500000000001, 0.8515750000000001], 'test_losses': [1.2196025148391723, 1.0209447473526, 0.963085073184967, 0.9256652258634567, 0.9042101866483688, 0.896624885892868, 0.8913617966413498, 0.8885338812589645, 0.8867997180223465, 0.8862530316591263], 'test_accuracies': [0.6664, 0.7109000000000001, 0.7249, 0.7354, 0.7425, 0.7439, 0.745, 0.7462000000000001, 0.7468, 0.7467], 'time_sec': 216.67}\n"
          ]
        }
      ],
      "source": [
        "\"\"\" QUICK HEAD TRAINING for the VALIDATION \"\"\"\n",
        "\n",
        "set_seed(seed=123)\n",
        "N_EP = 10\n",
        "T_MAX = N_EP\n",
        "LR = 0.001\n",
        "MOMENTUM = 0.8\n",
        "WEIGHT_DECAY = 5e-6\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === MODEL ===\n",
        "dino_vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "dino_vits16.eval()  # evaluation mode for the backbone\n",
        "dino_vits16 = dino_vits16.to(device)\n",
        "\n",
        "# Freeze backbone params\n",
        "for param in dino_vits16.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Create the final model (trainable head)\n",
        "model_central = DINOWithHead(dino_vits16, num_classes=100).to(device)\n",
        "for param in model_central.head.parameters():\n",
        "            param.requires_grad = True\n",
        "model_central.head.train()   # Training mode for head\n",
        "\n",
        "# === LOSS, OPTIMIZER, SCHEDULER ===\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "      model_central.head.parameters(), # We optimize only the head\n",
        "      lr=LR,\n",
        "      momentum=MOMENTUM,\n",
        "      weight_decay=WEIGHT_DECAY\n",
        "      )\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX)\n",
        "\n",
        "checkpoint_path = None\n",
        "\n",
        "start_time = time.time()\n",
        "final_model, train_losses, test_losses, train_accuracies, test_accuracies = train_test_model(\n",
        "    model_central,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    train_loader,       # trianing set\n",
        "    val_test_loader=val_loader,       # validation set\n",
        "    num_epochs=N_EP,\n",
        "    checkpoint_path=checkpoint_path,\n",
        ")\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# === SAVING RESULTS ===\n",
        "results = {\n",
        "    \"epochs\": N_EP,\n",
        "    \"train_losses\": train_losses,\n",
        "    \"train_accuracies\": train_accuracies,\n",
        "    \"test_losses\": test_losses,\n",
        "    \"test_accuracies\": test_accuracies,\n",
        "    \"time_sec\": round(elapsed_time, 2)\n",
        "}\n",
        "print(results)\n",
        "\n",
        "json_filename = \"results_central_VALIDATION.json\"\n",
        "\n",
        "with open(json_filename, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "torch.save(final_model.state_dict(), \"final_model_weights_VALIDATION.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QiKX7Na6W1z"
      },
      "outputs": [],
      "source": [
        "def wandb_train_sparse(config=None, pretrained_weights=None, train_loader=None, val_loader=None, verbose = False):\n",
        "\n",
        "    with wandb.init(config=config, reinit=True):\n",
        "        config = wandb.config\n",
        "\n",
        "        # === MODEL ===\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        dino_vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "        dino_vits16.train()  # train mode for the backbone\n",
        "        dino_vits16 = dino_vits16.to(device)\n",
        "\n",
        "        # Create the final model and log pre-trianed weights\n",
        "        model = DINOWithHead(dino_vits16, num_classes=100).to(device)\n",
        "        checkpoint = torch.load(pretrained_weights, map_location=device)\n",
        "        model.load_state_dict(checkpoint)\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"head\" in name: #or \"norm\" in name or \"patch_embed\" in name:   # head: already pre-trained\n",
        "                                                                              # norm: small changes here can distort global statistics\n",
        "                                                                              # patch_embed: initial representation => risk of degradating features\n",
        "                param.requires_grad = False\n",
        "            else:\n",
        "                param.requires_grad = True\n",
        "        model.head.eval()   # evaluation mode for the ehad\n",
        "\n",
        "        # === CHECK FROZEN ===\n",
        "        # frozen = [n for n,p in model.named_parameters() if not p.requires_grad]\n",
        "        # trainable = [n for n,p in model.named_parameters() if p.requires_grad]\n",
        "        # print(f\"Frozen params: {frozen}\")\n",
        "        # print(f\"Trainable params: {trainable}\")\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # === CALIBRATION: compute fisher mask ===\n",
        "        start_calib = time.time()\n",
        "        print(\"Calibration...\")\n",
        "        mask = None\n",
        "        if config.target_sparsity > 0:\n",
        "            print(f\"Applying Fisher mask with sparsity {config.target_sparsity}\")\n",
        "            mask = calibrate_mask_centralized(model, train_loader, device, R=config.rounds, final_sparsity=config.target_sparsity,\n",
        "                                                      lr=config.lr, keep=config.keep, do_train=True, max_batches=config.max_batches)\n",
        "\n",
        "            optimizer = SparseSGD(\n",
        "                list(model.named_parameters()),\n",
        "                lr=config.lr,\n",
        "                momentum=config.momentum,\n",
        "                weight_decay=config.weight_decay,\n",
        "                mask=mask\n",
        "            )\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr=config.lr,\n",
        "                            momentum=config.momentum,\n",
        "                            weight_decay=config.weight_decay)\n",
        "\n",
        "        end_calib = time.time()     # end timer\n",
        "        calib_time = end_calib - start_calib\n",
        "        print(f\"Fisher mask calibration took {calib_time:.2f} seconds\")\n",
        "\n",
        "        # === LOSS, SPARSE OPTIMIZER, SCHEDULER ===\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        #for i, m in enumerate(mask):\n",
        "        #    n_active = m.sum().item()\n",
        "        #   total = m.numel()\n",
        "        #   print(f\"Param {i}: {n_active}/{total} ({n_active/total:.3f})\")\n",
        "        #for name, m in mask_dict.items():\n",
        "        #   ratio = m.sum().item() / m.numel()\n",
        "        #    print(f\"{name}: {ratio:.3f}\")\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
        "\n",
        "\n",
        "        # === TRAIN ===\n",
        "        model, train_losses, val_losses, train_accs, val_accs = train_test_model(\n",
        "            model,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            num_epochs=config.epochs,\n",
        "            verbose=config.verbose\n",
        "        )\n",
        "\n",
        "        # === LOG ===\n",
        "        for epoch in range(config.epochs):\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"train_loss\": train_losses[epoch],\n",
        "                \"val_loss\": val_losses[epoch] if val_losses else None,\n",
        "                \"train_accuracy\": train_accs[epoch],\n",
        "                \"val_accuracy\": val_accs[epoch] if val_accs else None,\n",
        "            })\n",
        "\n",
        "        # === BEST LOG ===\n",
        "        if val_accs:\n",
        "            best_idx = val_accs.index(max(val_accs))\n",
        "\n",
        "            wandb.run.summary[\"best_val_accuracy\"] = val_accs[best_idx]\n",
        "            wandb.run.summary[\"best_val_loss\"] = val_losses[best_idx]\n",
        "            wandb.run.summary[\"best_train_accuracy\"] = train_accs[best_idx]\n",
        "            wandb.run.summary[\"best_train_loss\"] = train_losses[best_idx]\n",
        "            wandb.run.summary[\"calibration_time_sec\"] = calib_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0RPz15w0SdN",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### Parameter Grid - High sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Ka3--UAG0SdN",
        "outputId": "5c81d1f3-21b0-40c3-ef10-df0f48207985"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriele_\u001b[0m (\u001b[33mgabriele-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: xaqu0vzw\n",
            "Sweep URL: https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw\n"
          ]
        }
      ],
      "source": [
        "wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',    # probabilistic model (based on previous results, it predicts which hyperparameter combinations are likely to lead to better performance)\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'distribution': 'log_uniform_values',   # log_uniform as numbers are small\n",
        "            'min': 0.0001,\n",
        "            'max': 0.01\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'value': 64\n",
        "        },\n",
        "        'momentum': {\n",
        "            'values': [0.8, 0.9]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'distribution': 'log_uniform_values',    # log_uniform as numbers are small\n",
        "            'min': 1e-6,\n",
        "            'max': 1e-4\n",
        "        },\n",
        "        'epochs': {\n",
        "            'value': 7\n",
        "        },\n",
        "        'target_sparsity': {\n",
        "            'values': [0.8, 0.9]\n",
        "        },\n",
        "        'rounds': {\n",
        "            'value': 1\n",
        "        },\n",
        "        'max_batches': {\n",
        "            'values': [20]\n",
        "        },\n",
        "        'verbose': {\n",
        "            'value': True\n",
        "        },\n",
        "        'keep': {\n",
        "            'value': 'least'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Project_Sparse_Grid_High\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JHVtKb_W0SdN",
        "outputId": "a2e4484e-004d-46e7-977b-6424b841d084"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b4s28pih with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0010032743832587992\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.41967039603487e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_165556-b4s28pih</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/b4s28pih' target=\"_blank\">restful-sweep-1</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/b4s28pih' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/b4s28pih</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_41328/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.8\n",
            "[Mask Round 1] Sparsity: 0.8000\n",
            "Fisher mask calibration took 49.88 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.8129 Train Acc: 0.7568\n",
            "Val/Test Loss: 0.6938 Acc: 0.7855\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.4725 Train Acc: 0.8505\n",
            "Val/Test Loss: 0.6232 Acc: 0.8057\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.2927 Train Acc: 0.9098\n",
            "Val/Test Loss: 0.5936 Acc: 0.8192\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.1687 Train Acc: 0.9551\n",
            "Val/Test Loss: 0.5607 Acc: 0.8303\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.0983 Train Acc: 0.9823\n",
            "Val/Test Loss: 0.5581 Acc: 0.8319\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.0682 Train Acc: 0.9929\n",
            "Val/Test Loss: 0.5576 Acc: 0.8329\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.0576 Train Acc: 0.9955\n",
            "Val/Test Loss: 0.5590 Acc: 0.8342\n",
            "\n",
            "Training complete in 6m 29s\n",
            "Best Acc: 0.8342, Best Loss: 0.5590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▇███</td></tr><tr><td>train_loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇███</td></tr><tr><td>val_loss</td><td>█▄▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.99545</td></tr><tr><td>best_train_loss</td><td>0.05763</td></tr><tr><td>best_val_accuracy</td><td>0.8342</td></tr><tr><td>best_val_loss</td><td>0.55902</td></tr><tr><td>calibration_time_sec</td><td>49.88009</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.99545</td></tr><tr><td>train_loss</td><td>0.05763</td></tr><tr><td>val_accuracy</td><td>0.8342</td></tr><tr><td>val_loss</td><td>0.55902</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">restful-sweep-1</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/b4s28pih' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/b4s28pih</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_165556-b4s28pih/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3rvj4m2s with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00016698364717152784\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.205034039496119e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_170326-3rvj4m2s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/3rvj4m2s' target=\"_blank\">wobbly-sweep-2</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/3rvj4m2s' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/3rvj4m2s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.8\n",
            "[Mask Round 1] Sparsity: 0.8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_41328/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fisher mask calibration took 50.97 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.7011 Train Acc: 0.7894\n",
            "Val/Test Loss: 0.6232 Acc: 0.8094\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.4870 Train Acc: 0.8486\n",
            "Val/Test Loss: 0.5843 Acc: 0.8213\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.3798 Train Acc: 0.8833\n",
            "Val/Test Loss: 0.5771 Acc: 0.8232\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.3011 Train Acc: 0.9126\n",
            "Val/Test Loss: 0.5554 Acc: 0.8300\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.2456 Train Acc: 0.9342\n",
            "Val/Test Loss: 0.5536 Acc: 0.8348\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.2118 Train Acc: 0.9485\n",
            "Val/Test Loss: 0.5500 Acc: 0.8347\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.1946 Train Acc: 0.9557\n",
            "Val/Test Loss: 0.5501 Acc: 0.8360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 26s\n",
            "Best Acc: 0.8360, Best Loss: 0.5501\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆███</td></tr><tr><td>val_loss</td><td>█▄▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.9557</td></tr><tr><td>best_train_loss</td><td>0.19456</td></tr><tr><td>best_val_accuracy</td><td>0.836</td></tr><tr><td>best_val_loss</td><td>0.55012</td></tr><tr><td>calibration_time_sec</td><td>50.97492</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.9557</td></tr><tr><td>train_loss</td><td>0.19456</td></tr><tr><td>val_accuracy</td><td>0.836</td></tr><tr><td>val_loss</td><td>0.55012</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wobbly-sweep-2</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/3rvj4m2s' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/3rvj4m2s</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_170326-3rvj4m2s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ec42s5g4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001921924501734435\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 9.706911642308908e-05\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_171052-ec42s5g4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/ec42s5g4' target=\"_blank\">twilight-sweep-3</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/ec42s5g4' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/ec42s5g4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_41328/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.9\n",
            "[Mask Round 1] Sparsity: 0.9000\n",
            "Fisher mask calibration took 50.82 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.8077 Train Acc: 0.7595\n",
            "Val/Test Loss: 0.6394 Acc: 0.8038\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.5252 Train Acc: 0.8363\n",
            "Val/Test Loss: 0.6344 Acc: 0.8089\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.3727 Train Acc: 0.8840\n",
            "Val/Test Loss: 0.5577 Acc: 0.8299\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.2534 Train Acc: 0.9246\n",
            "Val/Test Loss: 0.5639 Acc: 0.8281\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.1789 Train Acc: 0.9526\n",
            "Val/Test Loss: 0.5562 Acc: 0.8325\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.1322 Train Acc: 0.9716\n",
            "Val/Test Loss: 0.5509 Acc: 0.8359\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.1120 Train Acc: 0.9808\n",
            "Val/Test Loss: 0.5461 Acc: 0.8375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 23s\n",
            "Best Acc: 0.8375, Best Loss: 0.5461\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▆▆▇██</td></tr><tr><td>val_loss</td><td>██▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.98075</td></tr><tr><td>best_train_loss</td><td>0.11195</td></tr><tr><td>best_val_accuracy</td><td>0.8375</td></tr><tr><td>best_val_loss</td><td>0.54608</td></tr><tr><td>calibration_time_sec</td><td>50.82332</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.98075</td></tr><tr><td>train_loss</td><td>0.11195</td></tr><tr><td>val_accuracy</td><td>0.8375</td></tr><tr><td>val_loss</td><td>0.54608</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">twilight-sweep-3</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/ec42s5g4' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/ec42s5g4</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_171052-ec42s5g4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gltmzkm0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005754899028159509\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 4.885902844661093e-05\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_171813-gltmzkm0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/gltmzkm0' target=\"_blank\">glamorous-sweep-4</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/gltmzkm0' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/gltmzkm0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_41328/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.8\n",
            "[Mask Round 1] Sparsity: 0.8000\n",
            "Fisher mask calibration took 50.60 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 3.9637 Train Acc: 0.0961\n",
            "Val/Test Loss: 3.6377 Acc: 0.1422\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 3.3718 Train Acc: 0.1878\n",
            "Val/Test Loss: 3.2120 Acc: 0.2174\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 2.5541 Train Acc: 0.3444\n",
            "Val/Test Loss: 1.5729 Acc: 0.5557\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 1.1920 Train Acc: 0.6547\n",
            "Val/Test Loss: 1.3002 Acc: 0.6243\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.6169 Train Acc: 0.8107\n",
            "Val/Test Loss: 0.9678 Acc: 0.7148\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.2610 Train Acc: 0.9171\n",
            "Val/Test Loss: 0.8648 Acc: 0.7585\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.0984 Train Acc: 0.9756\n",
            "Val/Test Loss: 0.7787 Acc: 0.7855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 22s\n",
            "Best Acc: 0.7855, Best Loss: 0.7787\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▂▃▅▇██</td></tr><tr><td>train_loss</td><td>█▇▅▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▅▆▇██</td></tr><tr><td>val_loss</td><td>█▇▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.97555</td></tr><tr><td>best_train_loss</td><td>0.09838</td></tr><tr><td>best_val_accuracy</td><td>0.7855</td></tr><tr><td>best_val_loss</td><td>0.77866</td></tr><tr><td>calibration_time_sec</td><td>50.5951</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.97555</td></tr><tr><td>train_loss</td><td>0.09838</td></tr><tr><td>val_accuracy</td><td>0.7855</td></tr><tr><td>val_loss</td><td>0.77866</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glamorous-sweep-4</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/gltmzkm0' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/gltmzkm0</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_171813-gltmzkm0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhuofpau with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005232212761533024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 7.12135932919634e-05\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_172532-bhuofpau</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/bhuofpau' target=\"_blank\">stilted-sweep-5</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/sweeps/xaqu0vzw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/bhuofpau' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/bhuofpau</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_41328/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.9\n",
            "[Mask Round 1] Sparsity: 0.9000\n",
            "Fisher mask calibration took 50.49 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.6991 Train Acc: 0.7919\n",
            "Val/Test Loss: 0.6185 Acc: 0.8138\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.5180 Train Acc: 0.8390\n",
            "Val/Test Loss: 0.5806 Acc: 0.8249\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.4339 Train Acc: 0.8655\n",
            "Val/Test Loss: 0.5697 Acc: 0.8260\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.3709 Train Acc: 0.8876\n",
            "Val/Test Loss: 0.5548 Acc: 0.8303\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.3232 Train Acc: 0.9057\n",
            "Val/Test Loss: 0.5575 Acc: 0.8314\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.2924 Train Acc: 0.9177\n",
            "Val/Test Loss: 0.5511 Acc: 0.8330\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.2756 Train Acc: 0.9250\n",
            "Val/Test Loss: 0.5511 Acc: 0.8320\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 26s\n",
            "Best Acc: 0.8330, Best Loss: 0.5511\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.91768</td></tr><tr><td>best_train_loss</td><td>0.29242</td></tr><tr><td>best_val_accuracy</td><td>0.833</td></tr><tr><td>best_val_loss</td><td>0.55105</td></tr><tr><td>calibration_time_sec</td><td>50.48658</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.925</td></tr><tr><td>train_loss</td><td>0.27561</td></tr><tr><td>val_accuracy</td><td>0.832</td></tr><tr><td>val_loss</td><td>0.55107</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stilted-sweep-5</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/bhuofpau' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High/runs/bhuofpau</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_High</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_172532-bhuofpau/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.agent(\n",
        "    sweep_id,\n",
        "    function=lambda: wandb_train_sparse(\n",
        "        pretrained_weights=\"final_model_weights_VALIDATION.pth\",\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader\n",
        "    ),\n",
        "    count=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gCUA67z6W1z"
      },
      "source": [
        "### Parameter Grid - Low sparsity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3Nl83E_6W10",
        "outputId": "6fde9134-fc08-4dc6-d287-f585a9f7e67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: mc0bcsnf\n",
            "Sweep URL: https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf\n"
          ]
        }
      ],
      "source": [
        "wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',    # probabilistic model (based on previous results, it predicts which hyperparameter combinations are likely to lead to better performance)\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'distribution': 'log_uniform_values',   # log_uniform as numbers are small\n",
        "            'min': 0.000001,\n",
        "            'max': 0.001\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'value': 64\n",
        "        },\n",
        "        'momentum': {\n",
        "            'values': [0.8, 0.9]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'distribution': 'log_uniform_values',    # log_uniform as numbers are small\n",
        "            'min': 1e-6,\n",
        "            'max': 1e-4\n",
        "        },\n",
        "        'epochs': {\n",
        "            'value': 7\n",
        "        },\n",
        "        'target_sparsity': {\n",
        "            'values': [0.2, 0.3]\n",
        "        },\n",
        "        'rounds': {\n",
        "            'value': 1\n",
        "        },\n",
        "        'max_batches': {\n",
        "            'values': [20]\n",
        "        },\n",
        "        'verbose': {\n",
        "            'value': True\n",
        "        },\n",
        "        'keep': {\n",
        "            'value': 'least'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Project_Sparse_Grid_Low\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt-usU606W10",
        "outputId": "22bcb89f-6891-4cca-fabc-1c5f255e7529"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 143y4eyt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 3.231532659282642e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.5826113863967493e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "creating run (22s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_211609-143y4eyt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/143y4eyt' target=\"_blank\">desert-sweep-1</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/143y4eyt' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/143y4eyt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_164757/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.3\n",
            "[Mask Round 1] Target Sparsity: 0.3000\n",
            "Totale parametri attivi nella mask: 15165964 / 21665664 (70.00%)\n",
            "Fisher mask calibration took 50.78 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.5346 Train Acc: 0.8421\n",
            "Val/Test Loss: 0.5120 Acc: 0.8498\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.4507 Train Acc: 0.8655\n",
            "Val/Test Loss: 0.4978 Acc: 0.8518\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.3954 Train Acc: 0.8835\n",
            "Val/Test Loss: 0.4925 Acc: 0.8536\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.3556 Train Acc: 0.8982\n",
            "Val/Test Loss: 0.4901 Acc: 0.8539\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.3288 Train Acc: 0.9090\n",
            "Val/Test Loss: 0.4891 Acc: 0.8534\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.3130 Train Acc: 0.9151\n",
            "Val/Test Loss: 0.4887 Acc: 0.8531\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.3056 Train Acc: 0.9172\n",
            "Val/Test Loss: 0.4886 Acc: 0.8532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 23s\n",
            "Best Acc: 0.8539, Best Loss: 0.4901\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.8982</td></tr><tr><td>best_train_loss</td><td>0.35564</td></tr><tr><td>best_val_accuracy</td><td>0.8539</td></tr><tr><td>best_val_loss</td><td>0.49006</td></tr><tr><td>calibration_time_sec</td><td>50.78019</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.91718</td></tr><tr><td>train_loss</td><td>0.30556</td></tr><tr><td>val_accuracy</td><td>0.8532</td></tr><tr><td>val_loss</td><td>0.48862</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">desert-sweep-1</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/143y4eyt' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/143y4eyt</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_211609-143y4eyt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vrs9rd8a with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 2.4372203058485064e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.917469047724878e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_212353-vrs9rd8a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/vrs9rd8a' target=\"_blank\">divine-sweep-2</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/vrs9rd8a' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/vrs9rd8a</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_164757/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.2\n",
            "[Mask Round 1] Target Sparsity: 0.2000\n",
            "Totale parametri attivi nella mask: 17332531 / 21665664 (80.00%)\n",
            "Fisher mask calibration took 52.26 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.5568 Train Acc: 0.8361\n",
            "Val/Test Loss: 0.5392 Acc: 0.8439\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.5214 Train Acc: 0.8461\n",
            "Val/Test Loss: 0.5282 Acc: 0.8455\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.4998 Train Acc: 0.8517\n",
            "Val/Test Loss: 0.5218 Acc: 0.8472\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.4842 Train Acc: 0.8564\n",
            "Val/Test Loss: 0.5180 Acc: 0.8479\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.4736 Train Acc: 0.8595\n",
            "Val/Test Loss: 0.5159 Acc: 0.8480\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.4673 Train Acc: 0.8613\n",
            "Val/Test Loss: 0.5149 Acc: 0.8482\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.4644 Train Acc: 0.8622\n",
            "Val/Test Loss: 0.5147 Acc: 0.8483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 14s\n",
            "Best Acc: 0.8483, Best Loss: 0.5147\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇███</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.86215</td></tr><tr><td>best_train_loss</td><td>0.46435</td></tr><tr><td>best_val_accuracy</td><td>0.8483</td></tr><tr><td>best_val_loss</td><td>0.51468</td></tr><tr><td>calibration_time_sec</td><td>52.2597</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.86215</td></tr><tr><td>train_loss</td><td>0.46435</td></tr><tr><td>val_accuracy</td><td>0.8483</td></tr><tr><td>val_loss</td><td>0.51468</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">divine-sweep-2</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/vrs9rd8a' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/vrs9rd8a</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_212353-vrs9rd8a/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fwyz08yd with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 5.759944721447012e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 3.072055659566905e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_213106-fwyz08yd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/fwyz08yd' target=\"_blank\">efficient-sweep-3</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/fwyz08yd' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/fwyz08yd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_164757/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.2\n",
            "[Mask Round 1] Target Sparsity: 0.2000\n",
            "Totale parametri attivi nella mask: 17332531 / 21665664 (80.00%)\n",
            "Fisher mask calibration took 50.45 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.5186 Train Acc: 0.8447\n",
            "Val/Test Loss: 0.4910 Acc: 0.8543\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.3591 Train Acc: 0.8956\n",
            "Val/Test Loss: 0.4820 Acc: 0.8546\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.2647 Train Acc: 0.9308\n",
            "Val/Test Loss: 0.4808 Acc: 0.8544\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.2051 Train Acc: 0.9535\n",
            "Val/Test Loss: 0.4847 Acc: 0.8525\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.1704 Train Acc: 0.9664\n",
            "Val/Test Loss: 0.4862 Acc: 0.8516\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.1519 Train Acc: 0.9735\n",
            "Val/Test Loss: 0.4869 Acc: 0.8519\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.1438 Train Acc: 0.9764\n",
            "Val/Test Loss: 0.4875 Acc: 0.8519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training complete in 6m 11s\n",
            "Best Acc: 0.8546, Best Loss: 0.4820\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇██</td></tr><tr><td>train_loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▇██▃▁▂▂</td></tr><tr><td>val_loss</td><td>█▂▁▄▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.89563</td></tr><tr><td>best_train_loss</td><td>0.35913</td></tr><tr><td>best_val_accuracy</td><td>0.8546</td></tr><tr><td>best_val_loss</td><td>0.48198</td></tr><tr><td>calibration_time_sec</td><td>50.44975</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.97643</td></tr><tr><td>train_loss</td><td>0.14378</td></tr><tr><td>val_accuracy</td><td>0.8519</td></tr><tr><td>val_loss</td><td>0.4875</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-sweep-3</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/fwyz08yd' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/fwyz08yd</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_213106-fwyz08yd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b8t9kblf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 6.05649595492581e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.710005772392436e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_213813-b8t9kblf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/b8t9kblf' target=\"_blank\">happy-sweep-4</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/b8t9kblf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/b8t9kblf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_164757/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.3\n",
            "[Mask Round 1] Target Sparsity: 0.3000\n",
            "Totale parametri attivi nella mask: 15165964 / 21665664 (70.00%)\n",
            "Fisher mask calibration took 50.49 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.5251 Train Acc: 0.8426\n",
            "Val/Test Loss: 0.4994 Acc: 0.8509\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.3989 Train Acc: 0.8826\n",
            "Val/Test Loss: 0.4885 Acc: 0.8538\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.3183 Train Acc: 0.9119\n",
            "Val/Test Loss: 0.4867 Acc: 0.8534\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.2641 Train Acc: 0.9315\n",
            "Val/Test Loss: 0.4846 Acc: 0.8533\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.2299 Train Acc: 0.9454\n",
            "Val/Test Loss: 0.4848 Acc: 0.8537\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.2107 Train Acc: 0.9524\n",
            "Val/Test Loss: 0.4852 Acc: 0.8534\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.2020 Train Acc: 0.9562\n",
            "Val/Test Loss: 0.4853 Acc: 0.8533\n",
            "\n",
            "Training complete in 6m 12s\n",
            "Best Acc: 0.8538, Best Loss: 0.4885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇██</td></tr><tr><td>train_loss</td><td>█▅▄▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁█▇▇█▇▇</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.88257</td></tr><tr><td>best_train_loss</td><td>0.39892</td></tr><tr><td>best_val_accuracy</td><td>0.8538</td></tr><tr><td>best_val_loss</td><td>0.48846</td></tr><tr><td>calibration_time_sec</td><td>50.48786</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.95622</td></tr><tr><td>train_loss</td><td>0.20202</td></tr><tr><td>val_accuracy</td><td>0.8533</td></tr><tr><td>val_loss</td><td>0.48535</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">happy-sweep-4</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/b8t9kblf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/b8t9kblf</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_213813-b8t9kblf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e056f9ho with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep: least\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 8.620881643604889e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_batches: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trounds: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_sparsity: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tverbose: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.1864286139453503e-06\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/gabriele/Desktop/ML_project/CENTRAL_TEST/wandb/run-20250829_214530-e056f9ho</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/e056f9ho' target=\"_blank\">chocolate-sweep-5</a></strong> to <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/sweeps/mc0bcsnf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/e056f9ho' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/e056f9ho</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/gabriele/.cache/torch/hub/facebookresearch_dino_main\n",
            "/tmp/ipykernel_164757/3398087762.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pretrained_weights, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calibration...\n",
            "Applying Fisher mask with sparsity 0.3\n",
            "[Mask Round 1] Target Sparsity: 0.3000\n",
            "Totale parametri attivi nella mask: 15165964 / 21665664 (70.00%)\n",
            "Fisher mask calibration took 50.44 seconds\n",
            "Initializing new checkpoint at checkpoints/latest.pth\n",
            "\n",
            "Epoch 1/7\n",
            "------------------------------\n",
            "Train Loss: 0.5185 Train Acc: 0.8436\n",
            "Val/Test Loss: 0.4922 Acc: 0.8543\n",
            "\n",
            "Epoch 2/7\n",
            "------------------------------\n",
            "Train Loss: 0.3590 Train Acc: 0.8956\n",
            "Val/Test Loss: 0.4806 Acc: 0.8553\n",
            "\n",
            "Epoch 3/7\n",
            "------------------------------\n",
            "Train Loss: 0.2630 Train Acc: 0.9315\n",
            "Val/Test Loss: 0.4809 Acc: 0.8540\n",
            "\n",
            "Epoch 4/7\n",
            "------------------------------\n",
            "Train Loss: 0.2033 Train Acc: 0.9548\n",
            "Val/Test Loss: 0.4837 Acc: 0.8524\n",
            "\n",
            "Epoch 5/7\n",
            "------------------------------\n",
            "Train Loss: 0.1684 Train Acc: 0.9674\n",
            "Val/Test Loss: 0.4856 Acc: 0.8519\n",
            "\n",
            "Epoch 6/7\n",
            "------------------------------\n",
            "Train Loss: 0.1499 Train Acc: 0.9741\n",
            "Val/Test Loss: 0.4862 Acc: 0.8515\n",
            "\n",
            "Epoch 7/7\n",
            "------------------------------\n",
            "Train Loss: 0.1417 Train Acc: 0.9771\n",
            "Val/Test Loss: 0.4866 Acc: 0.8516\n",
            "\n",
            "Training complete in 6m 11s\n",
            "Best Acc: 0.8553, Best Loss: 0.4806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇██</td></tr><tr><td>train_loss</td><td>█▅▃▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆█▆▃▂▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▃▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_accuracy</td><td>0.89558</td></tr><tr><td>best_train_loss</td><td>0.35903</td></tr><tr><td>best_val_accuracy</td><td>0.8553</td></tr><tr><td>best_val_loss</td><td>0.4806</td></tr><tr><td>calibration_time_sec</td><td>50.43662</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_accuracy</td><td>0.97708</td></tr><tr><td>train_loss</td><td>0.14175</td></tr><tr><td>val_accuracy</td><td>0.8516</td></tr><tr><td>val_loss</td><td>0.48659</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">chocolate-sweep-5</strong> at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/e056f9ho' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid/runs/e056f9ho</a><br> View project at: <a href='https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid' target=\"_blank\">https://wandb.ai/gabriele-politecnico-di-torino/Project_Sparse_Grid_Mid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250829_214530-e056f9ho/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.agent(\n",
        "    sweep_id,\n",
        "    function=lambda: wandb_train_sparse(\n",
        "        pretrained_weights=\"final_model_weights_VALIDATION.pth\",\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader\n",
        "    ),\n",
        "    count=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6woSOs2U0SdR"
      },
      "source": [
        "## (2.II) Final model (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WQACVSk6W10"
      },
      "outputs": [],
      "source": [
        "set_seed(123)\n",
        "\n",
        "# === PARAMS ===\n",
        "SPARSITY = 0.5\n",
        "LR = 5e-4\n",
        "N_EP_HEAD = 50\n",
        "N_EP_BACKBONE = 100\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-5\n",
        "KEEP = 'least'\n",
        "MAX_B = 20\n",
        "C_ROUNDS = 2\n",
        "VERBOSE = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "results = {}\n",
        "\n",
        "\n",
        "# === CARICA DINO PRETRAINED ===\n",
        "print(\"Downloading DINO ViT-S/16...\")\n",
        "dino_vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "dino_vits16.eval()  # Backbone in eval mode\n",
        "dino_vits16 = dino_vits16.to(device)\n",
        "\n",
        "# === CREA MODELLO FINALE CON HEAD ===\n",
        "NUM_CLASSES = 100\n",
        "model = DINOWithHead(dino_vits16, num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# === Head-only  ===\n",
        "\n",
        "model_dino = copy.deepcopy(model).to(device)\n",
        "model_dino.head.train()   # Head in train mode\n",
        "\n",
        "\n",
        "for name, param in model_dino.named_parameters():\n",
        "    param.requires_grad = (\"head\" in name)  # Only head = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    [p for p in model_dino.parameters() if p.requires_grad],\n",
        "    lr=LR,\n",
        "    momentum=MOMENTUM,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EP_HEAD)\n",
        "\n",
        "start_time = time.time()\n",
        "model_best, _, test_losses_head, _, test_acc_head = train_test_model(\n",
        "    model_dino, criterion, optimizer, scheduler,\n",
        "    tot_train_loader, val_test_loader=test_loader,\n",
        "    num_epochs=N_EP_HEAD, checkpoint_path=None, verbose=VERBOSE\n",
        ")\n",
        "elapsed_head = time.time() - start_time\n",
        "print(f\"Finished head-only training in {elapsed_head:.2f}s\")\n",
        "\n",
        "\n",
        "########################\n",
        "# === Backbone-only  ===\n",
        "\n",
        "for name, param in model_best.named_parameters():    # Continuing with the same model\n",
        "    param.requires_grad = (\"head\" not in name)  # freeze head, free the rest\n",
        "model_best.train()\n",
        "model_best.head.eval()   # Head in eval mode\n",
        "\n",
        "\n",
        "\n",
        "print(\"Calibration for sparse backbone...\")\n",
        "mask = calibrate_mask_centralized(\n",
        "    model_best, tot_train_loader, device,\n",
        "    R=C_ROUNDS, final_sparsity=SPARSITY,\n",
        "    lr=LR, keep=KEEP, do_train=True, max_batches=MAX_B\n",
        ")\n",
        "\n",
        "optimizer = SparseSGD(\n",
        "    list(model_best.named_parameters()),\n",
        "    lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY,\n",
        "    mask=mask\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EP_BACKBONE)\n",
        "\n",
        "start_time = time.time()\n",
        "model_best_ft, _, test_losses_backbone, _, test_acc_backbone = train_test_model(\n",
        "    model_best, criterion, optimizer, scheduler,\n",
        "    tot_train_loader, val_test_loader=test_loader,\n",
        "    num_epochs=N_EP_BACKBONE, checkpoint_path=None, verbose=VERBOSE\n",
        ")\n",
        "elapsed_backbone = time.time() - start_time\n",
        "print(f\"Finished backbone sparse training in {elapsed_backbone:.2f}s\")\n",
        "\n",
        "results = {\n",
        "    \"head_only\": {\"test_losses\": test_losses_head, \"test_accuracies\": test_acc_head, \"time_sec\": elapsed_head},\n",
        "    \"backbone_sparse\": {\"test_losses\": test_losses_backbone, \"test_accuracies\": test_acc_backbone, \"time_sec\": elapsed_backbone}\n",
        "}\n",
        "\n",
        "with open(\"results_head_backbone.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s3rwM1n6W10"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Concatenate accuracies and losses\n",
        "acc_combined = results['head_only']['test_accuracies'] + results['backbone_sparse']['test_accuracies']\n",
        "loss_combined = results['head_only']['test_losses'] + results['backbone_sparse']['test_losses']\n",
        "\n",
        "# Epoch axis\n",
        "epochs = list(range(1, len(acc_combined)+1))\n",
        "\n",
        "# --- Plot Accuracy ---\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(epochs, acc_combined, color='royalblue', marker='o', label='Head-only + Sparse Backbone')\n",
        "plt.title(\"Test Accuracy over Epochs\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(loc='lower right')\n",
        "plt.xticks(range(0, len(epochs)+1, 5))  # solo numeri interi\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Plot Loss ---\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(epochs, loss_combined, color='seagreen', marker='x', label='Head-only + Sparse Backbone')\n",
        "plt.title(\"Test Loss over Epochs\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Test Loss\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(loc='upper right')\n",
        "plt.xticks(range(0, len(epochs)+1, 5))  # solo numeri interi\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# === Load the JSON file ===\n",
        "with open(\"results_head_backbone.json\", \"r\") as f:\n",
        "    results = json.load(f)\n",
        "results = results['backbone_sparse']\n",
        "# === Extract key information ===\n",
        "best_accuracy = max(results.get(\"test_accuracies\", []))\n",
        "best_loss = min(results.get(\"test_losses\", []))\n",
        "training_time = results.get(\"time_sec\", None)\n",
        "\n",
        "# === Print results ===\n",
        "print(f\"Best Accuracy: {best_accuracy}\")\n",
        "print(f\"Best Loss: {best_loss}\")\n",
        "print(f\"Training Time (s): {training_time}\")\n"
      ],
      "metadata": {
        "id": "T11IcwjeMpYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}